{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing all the necessary libraries\nimport os \nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\n\nfrom collections import OrderedDict #OrderedDict is a dictionary subclass that remembers the order that keys were first inserted.\nimport seaborn as sns # seaborn is a Python data visualization library based on matplotlib. Go to library for plotting.\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer # to measure the time required to run a function.\nfrom sklearn.metrics import roc_auc_score\n\n# for showing the images\nimport cv2 # tool for image processing and performing computer vision tasks. Open-source library used to perform the task of image detection between NORMAL and PNEUMONIA\nimport random # to generate everytime you run the code a different set of images in each pertaining batch\nrandom.seed(1) #used to generate random object in Python.","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:35:45.545114Z","iopub.execute_input":"2022-02-08T14:35:45.545453Z","iopub.status.idle":"2022-02-08T14:35:48.146825Z","shell.execute_reply.started":"2022-02-08T14:35:45.545374Z","shell.execute_reply":"2022-02-08T14:35:48.145957Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"root = '../input/chest-xray-pneumonia/chest_xray/chest_xray/'\n# (os.path.join() join one or more path components\ntrain_dir = os.path.join(root, 'train')\nval_dir = os.path.join(root, 'val')\ntest_dir = os.path.join(root, 'test')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:35:53.767617Z","iopub.execute_input":"2022-02-08T14:35:53.768412Z","iopub.status.idle":"2022-02-08T14:35:53.772628Z","shell.execute_reply.started":"2022-02-08T14:35:53.768374Z","shell.execute_reply":"2022-02-08T14:35:53.771936Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"classes = ['NORMAL', 'PNEUMONIA'] # defining the class name(s).\n\nfor c in classes: # created class\n    target_path = os.path.join(train_dir, c) # path. join method combines one or more path names into a single path\n    sample_normal = random.sample(os.listdir(os.path.join(train_dir, c)),6) # os.listdir used to get the list of all files and directories in the specified directory. os.path.join combines one or more path names into a single path\n    f,ax = plt.subplots(2,3,figsize=(15,9)) # figure and axis' . A function that returns a tuple (an immutable collection of values seperated by comma and enclosed by parenthesis) containing a figure and axes object(s\n\n    for i in range(6):\n        im = cv2.imread(os.path.join(target_path, sample_normal[i])) # cv2. imread() method loads an image from the specified file\n        ax[i//3,i%3].imshow(im) # Axes.imshow() function in axes module of matplotlib library is also used to display an image or data on a 2D regular roster\n        ax[i//3,i%3].axis('off') #Rather than using plt.axis('off') you should use ax.axis('off') where ax is a matplotlib.axes object. To do this for your code you simple need to add axarr[3,3].axis('off') and so on for each of your subplots.\n    f.suptitle(\"{} Lungs \".format(c), fontsize=25)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:35:58.868696Z","iopub.execute_input":"2022-02-08T14:35:58.869106Z","iopub.status.idle":"2022-02-08T14:36:02.491666Z","shell.execute_reply.started":"2022-02-08T14:35:58.869065Z","shell.execute_reply":"2022-02-08T14:36:02.491019Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([ # stated below are some of the transforms to manipulate the data in the required format\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(), # convert a PIL Image or numpy. ndarray to tensor \n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Using the mean and std of Imagenet is a common practice\n        # the images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n    ]),\n    'test': transforms.Compose([ # stated below are some of the transforms to manipulate the data in the required format\n        transforms.Resize((224,224)),\n        transforms.ToTensor(), # convert a PIL Image or numpy. ndarray to tensor \n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Using the mean and std of Imagenet is a common practice\n        # the images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n    ]),\n    'val': transforms.Compose([ # stated below are some of the transforms to manipulate the data in the required format\n        transforms.Resize((224,224)),\n        transforms.ToTensor(), # convert a PIL Image or numpy. ndarray to tensor \n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Using the mean and std of Imagenet is a common practice\n        # the images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:36:16.829036Z","iopub.execute_input":"2022-02-08T14:36:16.829722Z","iopub.status.idle":"2022-02-08T14:36:16.837627Z","shell.execute_reply.started":"2022-02-08T14:36:16.829685Z","shell.execute_reply":"2022-02-08T14:36:16.836566Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 32 # batch size defines the number of samples that will be propagated throughout the network\n# batch size controls the accuracy of the estimate of the error gradient when training neural networks\n# batch size of 32 means that 32 samples from the training dataset will be used to estimate the error gradient before the model weights are updated\ndata_sets = { # used datasets to train the model\n    'train': torchvision.datasets.ImageFolder(train_dir,data_transforms['train']),\n    'test': torchvision.datasets.ImageFolder(train_dir,data_transforms['test']),\n    'val': torchvision.datasets.ImageFolder(train_dir,data_transforms['val']),\n}\n\ndata_loaders = { # combines a dataset and a sampler, and provides an iterable over the given dataset\n    # num_workers=2 we have 2 workers simultaneously putting data into RAM. We did not want to overload so we went with 2\n    # By using shuffle=True you shuffle up the dataset which makes the training batches more generalized which in turn\n    # makes the  'train' and 'test' models more generalized. We used 'shuffle=False' for 'val' as there\n    # are 9 of each images in the NORMAL and PNEUMONIA folders\n    'train': DataLoader(data_sets['train'], batch_size=batch_size, shuffle=True, num_workers=2),\n    'val': DataLoader(data_sets['val'], batch_size=batch_size, shuffle=False, num_workers=2),\n    'test': DataLoader(data_sets['test'], batch_size=batch_size, shuffle=True, num_workers=2)\n}    ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T11:26:46.879992Z","iopub.execute_input":"2022-02-08T11:26:46.880872Z","iopub.status.idle":"2022-02-08T11:26:48.782739Z","shell.execute_reply.started":"2022-02-08T11:26:46.88082Z","shell.execute_reply":"2022-02-08T11:26:48.781985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# created directories\ndir_ = [train_dir, val_dir, test_dir]\nx = []\ny = []\n\nfor i in range(3): # created loop\n    # listdir() method used to get the list of all files and directories in the specified directory.\n    # If we don't specify any directory, then list of files and directories in the current working directory will be returned.\n    target_normal = os.listdir(os.path.join(dir_[i], 'NORMAL'))\n    target_pneumonia = os.listdir(os.path.join(dir_[i], 'PNEUMONIA'))\n    # _.append() adds a single item to the existing list.\n    # After executing the method append on the list the size of the list increases by one.\n    x.append(len(target_normal))\n    y.append(len(target_pneumonia))\n    \n    # 'os.path.basename' method returns a string value which represents the base name the specified path. \n    print(\"In {} folder... \\n normal:{} \\t pneumonia: {}\".format(os.path.basename(dir_[i]), x[i], y[i]))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:36:43.743945Z","iopub.execute_input":"2022-02-08T14:36:43.744756Z","iopub.status.idle":"2022-02-08T14:36:43.758375Z","shell.execute_reply.started":"2022-02-08T14:36:43.744703Z","shell.execute_reply":"2022-02-08T14:36:43.757557Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# We created a bar chart to depict the number of pictures in each cooresponding folder.\nlabels = ['train_file', 'val_file', 'test_file'] \nplt.figure(figsize=(12, 6))\nwidth = 0.30\nplt.bar(np.arange(len(x))- width/2, x, width, label=\"normal\")\nplt.bar(np.arange(len(x))+ width/2, y, width, label=\"pneumonia\")\nplt.xticks(np.arange(len(x)), labels, fontsize=14)\n\nplt.title(\"Overall Depiction of Chest-xray-Pneumonia Dataset\", fontsize=20) # title\nplt.show() # Display of bar chart","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:36:51.904011Z","iopub.execute_input":"2022-02-08T14:36:51.904496Z","iopub.status.idle":"2022-02-08T14:36:52.086868Z","shell.execute_reply.started":"2022-02-08T14:36:51.904459Z","shell.execute_reply":"2022-02-08T14:36:52.086219Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = models.densenet121(pretrained=True) # Input the densenet121 model\n\n# To get the parameter count of each layer our PyTorch has model.parameters() that returns an\n# iterator of both the parameter name and the parameter itself.\nfor param in model.parameters():\n    param.requires_grad = True # All layers have the parameters modified during training as \n    # 'requires_grad' is set to true. 'Import torch', torchvision 'import torch.nn as nn' from collections import.","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:36:59.747054Z","iopub.execute_input":"2022-02-08T14:36:59.747606Z","iopub.status.idle":"2022-02-08T14:37:01.740349Z","shell.execute_reply.started":"2022-02-08T14:36:59.747565Z","shell.execute_reply":"2022-02-08T14:37:01.739676Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.classifier = nn.Sequential(OrderedDict([ # Setting up to train our model(s).\n    ('fcl1', nn.Linear(1024,256)), # nn. Linear(n,m) is a module that creates single layer feed forward network with n inputs and m output\n    ('dp1', nn.Dropout(0.3)), # without nn.dropout run diverges a lot after just a few epochs. Hence it calls for the higher generalization error.\n    ('r1', nn.ReLU()), # Relu is an activation function. After each layer, an activation function needs to be applied so as to make the network non-linear.\n    ('fcl2', nn.Linear(256,32)), # nn. Linear(n,m) is a module that creates single layer feed forward network with n inputs and m output\n    ('dp2', nn.Dropout(0.3)), # without nn.dropout run diverges a lot after just a few epochs. Hence it calls for the higher generalization error.\n    ('r2', nn.ReLU()),  # Relu is an activation function. After each layer, an activation function needs to be applied so as to make the network non-linear.\n    ('fcl3', nn.Linear(32,2)), # nn. Linear(n,m) is a module that creates single layer feed forward network with n inputs and m output\n    ('out', nn.LogSoftmax(dim=1)), # a Softmax-based Activation Function is the logarithm of a Softmax Function\n]))  # We used Log Softmax as it is advantageous over softmax for numerical stability, optimisation and heavy penalisation for highly incorrect class.","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:37:10.560318Z","iopub.execute_input":"2022-02-08T14:37:10.560578Z","iopub.status.idle":"2022-02-08T14:37:10.571326Z","shell.execute_reply.started":"2022-02-08T14:37:10.560551Z","shell.execute_reply":"2022-02-08T14:37:10.570488Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = []\n\ndef train(model, train_loader, val_loader, criterion, optimizer, scheduler=None, train_on_gpu=False, num_epochs=30, save_file='model.pth'):\n    \n    overall_start = timer() # The time takes to run  \n    valid_loss_min= np.Inf  # Initialize tracker for minimum validation loss\n    \n    #  'Epoch' - One training epoch means that the learning algorithm\n    #            has made one pass through the training dataset.\n    \n    if train_on_gpu:\n        model.cuda() # it is not DataLoaders job to send anything directly to GPU, we explicitly call cuda() for that \n    for epoch in (1, num_epochs): # loop \n        train_loss = 0\n        val_loss = 0\n        \n        train_start = timer() \n              \n        if scheduler is not None: # In event we used a scheduler otherwise we set it to None\n            scheduler.step()\n        \n        # train region\n        \n        model.train()\n        for data, target in train_loader:\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n                # cuda is used to set up and run CUDA operations.\n                # It keeps track of the currently selected GPU, and\n                # all CUDA tensors you allocate will by default be created on that device.\n                # The selected device can be changed with a torch. cuda.\n                \n            optimizer.zero_grad() # Sets the gradients of all optimized torch\n\n            # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n            # Itâ€™s important to call this before loss.backward(), otherwise we accumulate\n            # the gradients from multiple passes.\n            output = model(data) # the output of the model data\n            loss = criterion(output, target)\n            loss.backward()  # computes the mean-squared error between the input and the target.\n            optimizer.step() # After computing the gradients for all tensors in the model, calling \n                             # optimizer. step() makes the optimizer iterate over all parameters (tensors)\n                             # it is supposed to update and use their internally stored grad to update\n                             # their values.\n            train_loss += loss.item() * data.size(0)\n            #  loss. item() contains the loss of entire mini-batch, but divided by the batch size.\n            #  That's why loss.item() is multiplied with batch size, given by inputs.\n            \n            # Track the training progress...\n            print(\n            f'Epoch: {epoch}\\t {timer() - train_start:.2f} seconds elapsed in training epoch.',\n            end='\\r')\n        \n        \n        print(f'Epoch: {epoch}\\t {timer() - train_start:.2f} seconds elapsed in training epoch.')\n        # val region \n                \n        model.eval()\n        number_correct, number_data = 0, 0\n        for data, target in val_loader: # loop\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n            output = model(data)\n            loss = criterion(output, target)\n            val_loss += loss.item() * data.size(0)\n            \n        # calculate accuracy\n            # values , indices = torch.max(output , 1)  --> max in row\n            _, pred = torch.max(output, 1)\n            correct_tensor = pred.eq(target.data.view_as(pred)) # Computes element-wise equality\n            correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu \\\n                                    else np.squeeze(correct_tensor.cpu().numpy()) # squeeze function in PyTorch is used for manipulating a tensor by dropping all its dimensions of inputs having size 1.\n            number_correct += sum(correct) # Returns the sum of each row of the sparse tensor input in the given dimensions dim\n            number_data += correct.shape[0]\n            \n            #Track eval & cal progress\n            print(\n            f'Epoch: {epoch}\\t {timer() - eval_start:.2f} seconds elapsed in validation epoch.',\n            end='\\r')\n        \n        train_loss = train_loss / len(train_loader.dataset)\n        val_loss = val_loss / len(val_loader.dataset)\n        accuracy = (100 * number_correct / number_data)\n        print(\"Epoch: {} \\n-----------------\\n \\tTraining Loss: {:.6f} \\t Validation Loss: {:.6f} \\t accuracy : {:.4f}% \".format(epoch, train_loss, val_loss, accuracy))\n        if val_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, val_loss))\n            torch.save(model.state_dict(), save_file)\n            valid_loss_min = val_loss\n            \n        total_time = timer() - overall_start\n        print(\n            f'{total_time:.2f} total seconds elapsed. {(total_time) / (epoch):.2f} seconds per epoch.'\n        )\n        \n        history.append({'train_loss': train_loss, 'val_loss': val_loss, 'acc' : accuracy})\n        # to append or save the history data in the train, val, and acc files\n               \n    model.to('cpu') #loading to the CPU\n    \n    return torch.load(save_file) # load and save model file\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:49:08.133352Z","iopub.execute_input":"2022-02-08T14:49:08.133689Z","iopub.status.idle":"2022-02-08T14:49:08.155416Z","shell.execute_reply.started":"2022-02-08T14:49:08.133653Z","shell.execute_reply":"2022-02-08T14:49:08.154522Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available() # Call function for running on GPU\nif train_on_gpu: #Created a loop in the event we wish to use the GPU over the CPU, for faster results.\n    print('GPU is  available. Training on GPU ...')\nelse:\n    print('GPU is not available. Training on CPU ...')\n    \n# If you need to move a model to GPU via .cuda()\n# please do so before constructing optimizers for it.\n# Parameters of a model after .cuda() will be different\n# objects with those before the call.    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T14:38:59.998895Z","iopub.execute_input":"2022-02-08T14:38:59.999152Z","iopub.status.idle":"2022-02-08T14:39:00.046322Z","shell.execute_reply.started":"2022-02-08T14:38:59.999123Z","shell.execute_reply":"2022-02-08T14:39:00.045362Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss() # 'nn. NLLLoss' expects the inputs to be log probabilities, while you are passing the probabilities into the criterion.\noptimizer = optim.Adadelta(model.parameters()) # An adaptive learning rate method 'Adadelta Algorithm' as our optimizer\nnum_epochs = 2 # number of epochs we chose to test our neural network\n\n# To construct an Optimizer you have to give it an iterable containing\n# the parameters (all should be Variable s) to optimize. Then, you can\n# specify optimizer-specific options such as the learning rate, etc.\n\nmodel_state_dict = train(\n                            model, #the model\n                            # our two dataLoaders 'train' and 'val'\n                            data_loaders['train'], \n                            data_loaders['val'],\n                            criterion=criterion, # Creates a criterion that measures the mean absolute value between n elements in the input x and output y\n                            optimizer=optimizer,# Optimization is the process of adjusting model parameters to reduce model error in each training step.\n                            scheduler=None, # We avoided a scheduler out of good practice :-). Otherwise, they are used to adjust only the hyperparameter of learning rate in a model. Early stopping refers to another hyperparameter, the number of train epochs.\n                            train_on_gpu=train_on_gpu,# Train on GPU\n                            num_epochs=num_epochs, # An epoch is a measure of the number of times all training data is used once to update the parameters. We want our neural networks to train quickly.\n                            )\n\nmodel.load_state_dict(model_state_dict) # Saving and loading the model...","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:30:12.973659Z","iopub.execute_input":"2022-02-06T23:30:12.97393Z","iopub.status.idle":"2022-02-06T23:36:54.224054Z","shell.execute_reply.started":"2022-02-06T23:30:12.9739Z","shell.execute_reply":"2022-02-06T23:36:54.222825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining test, printing\ndef test(model, test_loader, train_on_gpu, criterion, classes): \n    print('Commence Test')\n    test_loss = 0\n    class_correct = list(0. for i in range(len(classes)))\n    class_total = list(0. for i in range(len(classes)))\n    \n    if train_on_gpu:\n        model.cuda()\n    \n    # Evaluate model \n    test_start = timer()\n    model.eval()\n    cat_accuracy = {}\n    for data, target in test_loader:\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        loss = criterion(output, target)\n        test_loss += loss.item() * data.size(0)\n        \n        _, pred = torch.max(output, 1) \n        correct_tensor = pred.eq(target.data.view_as(pred))\n        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu \\\n                                else np.squeeze(correct_tensor.cpu().numpy())\n        \n        print(f'{timer() - test_start:.2f} seconds elapsed in test mode.',\n            end='\\r')\n        \n        for i in range(data.shape[0]):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n    test_loss = test_loss / len(test_loader.dataset)\n    print(\"Test Loss: {:.6f}\".format(test_loss))\n    print(\"Test Accuracy (Overall): %2d%% (%2d/%2d) \\n ----------------------\" % (100. * np.sum(class_correct) / np.sum(class_total),np.sum(class_correct), np.sum(class_total)))\n    for i in range(len(classes)):\n        if class_total[i] > 0:\n            print('Test Accuracy of %s : %d%% (%2d/%2d)' % (classes[i], 100 * class_correct[i] / class_total[i],np.sum(class_correct[i]), np.sum(class_total[i])))\n        else:\n            print('Test Accuracy of %s: N/A (no training examples)' % (classes[str(i+1)]))","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:37:42.405325Z","iopub.execute_input":"2022-02-06T23:37:42.406164Z","iopub.status.idle":"2022-02-06T23:37:42.423263Z","shell.execute_reply.started":"2022-02-06T23:37:42.406126Z","shell.execute_reply":"2022-02-06T23:37:42.421863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss() # Obtaining log-probabilities in a neural network is easily\n                         # achieved by adding a LogSoftmax layer in the last layer of\n                         # our network. \ntest(model, data_loaders['test'], train_on_gpu, criterion, classes) # Testing and loading our model on the computers GPU.","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:38:06.71936Z","iopub.execute_input":"2022-02-06T23:38:06.719724Z","iopub.status.idle":"2022-02-06T23:39:32.919268Z","shell.execute_reply.started":"2022-02-06T23:38:06.719678Z","shell.execute_reply":"2022-02-06T23:39:32.918188Z"},"trusted":true},"execution_count":null,"outputs":[]}]}